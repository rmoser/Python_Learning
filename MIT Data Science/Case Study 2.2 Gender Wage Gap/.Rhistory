install.packages("hdm")
install.packages("hdm", repos="http://R-Forge.R-project.org")
library("hdm")
data(pension)
help(pension)
View(pension)
vignette()
vignette("hdm")
source('F:/Users/Bob/Documents/Git/Python_Learning/MIT Data Science/Case Study 2.1 Predicting Wage 1/Regression1.4.CaseStudy.R', echo=TRUE)
cd()
cd
help cd
help
help("dir")
help("cd")
getwd()
rm(list=ls())
# Set directory(this should be set to user's own directory)
setwd("F:\Users\Bob\Documents\Git\Python_Learning\MIT Data Science\Case Study 2.1 Predicting Wage 1")
setwd("F:/Users/Bob/Documents/Git/Python_Learning/MIT Data Science/Case Study 2.1 Predicting Wage 1")
load(file="pay.discrimination.Rdata")
View(data)
View(data)
class(data)
str(data)
dim(data)
stats <- as.matrix(apply(data, 2, mean))
library(xtable)
install.packages("xtable")
library(xtable)
colnames(stats) = c("average")
xtable(stats)
fmla1     <-  wage ~ female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3
full.fit1 <-  lm(fmla1, data=data)
fit1      <-  summary(full.fit1)
R2.1      <-  fit1$r.squared
R2.adj1   <-  fit1$adj.r.squared
n1        <-  length(fit1$res)
p1        <-  fit1$df[1]
MSE.adj1  <-  (n1/(n1-p1))*mean(fit1$res^2)
fmla2     <- wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
full.fit2 <- lm(fmla2, data=data)
fit2      <- summary(full.fit2)
R2.2      <- fit2$r.squared
R2.adj2   <- fit2$adj.r.squared
n2        <- length(fit2$res)
p2        <- fit2$df[1]
MSE.adj2  <- (n2/(n2-p2))*mean(fit2$res^2)
# Summary of linear and quadratic specifications
table1     <- matrix(0, 2, 4)
table1[1,] <- c(p1, R2.1, R2.adj1, MSE.adj1)
table1[2,] <- c(p2, R2.2, R2.adj2, MSE.adj2)
colnames(table1) <- c("p", "R^2", "R^2 adj", "MSE adj")
rownames(table1) <- c("basic reg", "flex reg")
# set random number generator
set.seed(123)
# split data into training and test sample
train      <- sample(1:nrow(data), nrow(data)/2)
# run linear specification and compute MSE and R^2 for the test sample
full.fit1  <- lm(fmla1, data=data[train,])
yhat.fit1  <- predict(full.fit1, newdata=data[-train,])
y.test     <- data[-train,]$wage
MSE.fit1   <- summary(lm((y.test-yhat.fit1)^2~1))$coef[1]
R2.fit1    <- 1- MSE.fit1/var(y.test)
# split data into training and test sample
train      <- sample(1:nrow(data), nrow(data)/2)
# run quadratic specification and compute MSE and R^2 for the test sample
full.fit2  <- lm(fmla2, data=data[train,])
yhat.fit2  <- predict(full.fit2, newdata=data[-train,])
y.test     <- data[-train,]$wage
MSE.fit2   <- summary(lm((y.test-yhat.fit2)^2~1))$coef[1]
R2.fit2    <- 1- MSE.fit2/var(y.test)
# Create result table
table2      <- matrix(0, 2, 3)
table2[1,]  <- c(p1, R2.fit1, MSE.fit1)
table2[2,]  <- c(p2, R2.fit2, MSE.fit2)
# Give Columns and Row Names
colnames(table2)  <- c("p ", "R2 test", "MSE test")
rownames(table2)  <- c("basic reg", "flex reg")
# Print Results
print(table1,digits=4)
print(table2,digits=4)
View(data)
write.csv(data, file="Wages.csv")
View(table1)
View(table2)
View(stats)
fit1
fit2
full.fit1
full.fit2
print(table1,digits=4)
print(table2,digits=4)
# R code for Regression 1.6: Gender Waage Gap
# Clear workspace
rm(list=ls())
# Load xtable library to print table in .text format
library(xtable)
# Set Directory
setwd("F:/Users/Bob/Documents/Git/Python_Learning/MIT Data Science/Case Study 2.2 Gender Wage Gap")
# Load Dataset and see variables and the number of observations.
load(file="pay.discrimination.Rdata")
str(data)
dim(data)
attach(data)
stats.female  <- as.matrix(apply(data[female==1,], 2, mean))
View(stats.female)
View(data)
stats.male    <- as.matrix(apply(data[female==0,], 2, mean))
stats         <- cbind(stats.male, stats.female)
View(stats)
# Print basic stats
colnames(stats) = c("male averages", "female averages")
xtable(stats)
fmla1     <- wage ~  female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3
full.fit1 <- lm(fmla1, data=data)
est1      <- summary(full.fit1)$coef[2,1:2]
ci1       <-  confint(full.fit1)[2,]
# Wage linear regression
fmla1     <- wage ~  female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3
# Run OlS regression, get coefficients, standard errors and 95% confidence interval
full.fit1 <- lm(fmla1, data=data)
est1      <- summary(full.fit1)$coef[2,1:2]
ci1       <-  confint(full.fit1)[2,]
# Linear regression: Quadratic specification
fmla2     <-  wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
# Run OlS regression, get coefficients, standard errors and 95% confidence interval
full.fit2 <- lm(fmla2, data=data)
est2      <- summary(full.fit2)$coef[2,1:2]
ci2       <- confint(full.fit2)[2,]
#Create table to store regression results
table1     <- matrix(0, 2, 4)
table1[1,] <- c(est1,ci1)
table1[2,] <- c(est2,ci2)
#Give column and  row names
colnames(table1) <- c("Estimate", "Standard Error", "Lower Conf. Bound", "Upper Conf. Bound")
rownames(table1) <- c("basic reg", "flex reg")
############################ Illustration of Partialling Out: (Linear Specification)    ############################
# Linear regression of y (outcome) on covariates
fmla1.y <- wage ~  sc+ cg+ mw + so + we + exp1 + exp2 + exp3
# Linear regression of d (treatment) on covariates
fmla1.d <- female ~  sc+ cg+ mw + so + we + exp1 + exp2 + exp3
# Residuals of outcome regression
t.Y    <- lm(fmla1.y, data=data)$res
# Residuals of treatment regression
t.D    <-  lm(fmla1.d, data=data)$res
# Run OLS coefficient get coefficients and 95% confidence intervals
partial.fit1   <- lm(t.Y~t.D)
partial.est1   <- summary(partial.fit1)$coef[2,1:2]
partial.ci1    <- confint(partial.fit1)[2,]
############################ Illustration of Partialling Out: (Quadratic Specification)    ############################
fmla2.y  <- wage ~  (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
fmla2.d  <- female ~ (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
# get residuals from linear regression
t.Y  <- lm(fmla2.y, data=data)$res
t.D  <- lm(fmla2.d, data=data)$res
# regress residuals one onether to get result from partialled out regression
partial.fit2  <-  lm(t.Y~t.D)
partial.est2  <-  summary(partial.fit2)$coef[2,1:2]
partial.ci2   <-  confint(partial.fit2)[2,]
#Create table to store regression results
table2     <- matrix(0, 4, 2)
table2[1,] <- c(est1)
table2[2,] <- c(est2)
table2[3,] <- c(partial.est1)
table2[4,] <- c(partial.est2)
#Give column and row names
colnames(table2) <- c("Estimate", "Standard Error")
rownames(table2) <- c("basic reg", "flex reg", "basic reg with partialling out", "flex reg with partialling out")
#Print results
print(table1, digits=3)
print(table2, digits=3)
rm(list=ls())
library(xtable)
setwd("F:/Users/Bob/Documents/Git/Python_Learning/MIT Data Science/Case Study 2.2 Gender Wage Gap")
# Load Dataset and see variables and the number of observations.
load(file="pay.discrimination.Rdata")
str(data)
dim(data)
# Attach dataset to current workspace.
attach(data)
# Compute basic stats:
stats.female  <- as.matrix(apply(data[female==1,], 2, mean))
stats.male    <- as.matrix(apply(data[female==0,], 2, mean))
stats         <- cbind(stats.male, stats.female)
# Print basic stats
colnames(stats) = c("male averages", "female averages")
xtable(stats)
fmla1     <- wage ~  female + sc+ cg+ mw + so + we + exp1 + exp2 + exp3
# Run OlS regression, get coefficients, standard errors and 95% confidence interval
full.fit1 <- lm(fmla1, data=data)
est1      <- summary(full.fit1)$coef[2,1:2]
ci1       <-  confint(full.fit1)[2,]
# Linear regression: Quadratic specification
fmla2     <-  wage ~  female + (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
# Run OlS regression, get coefficients, standard errors and 95% confidence interval
full.fit2 <- lm(fmla2, data=data)
est2      <- summary(full.fit2)$coef[2,1:2]
ci2       <- confint(full.fit2)[2,]
#Create table to store regression results
table1     <- matrix(0, 2, 4)
table1[1,] <- c(est1,ci1)
table1[2,] <- c(est2,ci2)
View(table1)
colnames(table1) <- c("Estimate", "Standard Error", "Lower Conf. Bound", "Upper Conf. Bound")
rownames(table1) <- c("basic reg", "flex reg")
View(table1)
# Linear regression of y (outcome) on covariates
fmla1.y <- wage ~  sc+ cg+ mw + so + we + exp1 + exp2 + exp3
fmla1.d <- female ~  sc+ cg+ mw + so + we + exp1 + exp2 + exp3
t.Y    <- lm(fmla1.y, data=data)$res
t.D    <-  lm(fmla1.d, data=data)$res
partial.fit1   <- lm(t.Y~t.D)
partial.est1   <- summary(partial.fit1)$coef[2,1:2]
partial.ci1    <- confint(partial.fit1)[2,]
fmla2.y  <- wage ~  (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
fmla2.d  <- female ~ (sc+ cg+ mw + so + we + exp1 + exp2 + exp3)^2
# get residuals from linear regression
t.Y  <- lm(fmla2.y, data=data)$res
t.D  <- lm(fmla2.d, data=data)$res
# regress residuals one onether to get result from partialled out regression
partial.fit2  <-  lm(t.Y~t.D)
partial.est2  <-  summary(partial.fit2)$coef[2,1:2]
partial.ci2   <-  confint(partial.fit2)[2,]
table2     <- matrix(0, 4, 2)
table2[1,] <- c(est1)
table2[2,] <- c(est2)
table2[3,] <- c(partial.est1)
table2[4,] <- c(partial.est2)
colnames(table2) <- c("Estimate", "Standard Error")
rownames(table2) <- c("basic reg", "flex reg", "basic reg with partialling out", "flex reg with partialling out")
View(table2)
